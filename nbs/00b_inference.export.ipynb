{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/muellerzr/fastai2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp inference.export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference.export\n",
    "> This module contains the main functionality for extracting the transform parameters from DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example we will look at the pets dataset. We will define a series of transforms in our Pipelines, and we will attempt to extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "fnames = get_image_files(path/'images')\n",
    "pat = r'(.+)_\\d+.jpg$'\n",
    "batch_tfms = [*aug_transforms(size=224, max_warp=0.8), Normalize.from_stats(*imagenet_stats)]\n",
    "item_tfms = RandomResizedCrop(460, min_scale=0.75, ratio=(1.,1.))\n",
    "bs=64\n",
    "dls = ImageDataLoaders.from_name_re(path, fnames, pat, batch_tfms=batch_tfms, \n",
    "                                   item_tfms=item_tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell\n",
    "def to_list(b):\n",
    "    \"Recursively make any `L()` or CategoryMap to list\"\n",
    "    def _inner(o): \n",
    "        if isinstance(o,L) or isinstance(o, CategoryMap):\n",
    "            return list(o)\n",
    "        elif isinstance(o, Tensor):\n",
    "            return np.array(to_detach(o))\n",
    "        else: return o\n",
    "    for k in b.keys():\n",
    "        b[k] = apply(_inner,b[k])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _gen_dict(tfm):\n",
    "    \"Grabs the `attrdict` and transform name from `tfm`\"\n",
    "    tfm_dict = attrdict(tfm, *tfm.store_attrs.split(','))\n",
    "    if 'partial' in tfm.name:\n",
    "        tfm_name = tfm.name[1].split(' --')[0]\n",
    "    else:\n",
    "        tfm_name = tfm.name.split(' --')[0]\n",
    "    return tfm_dict, tfm_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_tfm_dict(tfms, type_tfm=False):\n",
    "    \"Extracts transform params from `tfms`\"\n",
    "    tfm_dicts = {}\n",
    "    for tfm in tfms:\n",
    "        if hasattr(tfm, 'store_attrs') and not isinstance(tfm, AffineCoordTfm):\n",
    "            if type_tfm or tfm.split_idx is not 0:\n",
    "                tfm_dict,name = _gen_dict(tfm)\n",
    "                tfm_dict = to_list(tfm_dict)\n",
    "                tfm_dicts[name] = tfm_dict\n",
    "    return tfm_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(_make_tfm_dict(dls.tfms, True)), 1)\n",
    "ab_dict = _make_tfm_dict(dls.after_batch)\n",
    "in_('Normalize', ab_dict.keys());\n",
    "not in_('Flip', ab_dict.keys());\n",
    "it_dict = _make_tfm_dict(dls.after_item)\n",
    "in_('RandomResizedCrop', ab_dict.keys())\n",
    "not in_('ToTensor', ab_dict.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def _extract_tfm_dicts(dl:TfmdDL):\n",
    "    \"Extracts all transform params from `dl`\"\n",
    "    type_tfm = True\n",
    "    attrs = ['tfms','after_item','after_batch']\n",
    "    tfm_dicts = {}\n",
    "    for attr in attrs:\n",
    "        tfm_dicts[attr] = _make_tfm_dict(getattr(dl, attr), type_tfm)\n",
    "        if attr == 'after_item': tfm_dicts[attr]['ToTensor'] = True\n",
    "        type_tfm = False\n",
    "    return tfm_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_information(dls): return _extract_tfm_dicts(dls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_information\n",
    "\n",
    "This function will take any set of `DataLoaders` and extract the transforms which are important during inference and their information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_info = get_information(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(tfm_info),3)\n",
    "test_eq(tfm_info.keys(), ['tfms','after_item','after_batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vision it will contain `tfms`, `after_item`, and `after_batch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, our `type` transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categorize': {'add_na': False,\n",
       "  'vocab': ['Abyssinian',\n",
       "   'Bengal',\n",
       "   'Birman',\n",
       "   'Bombay',\n",
       "   'British_Shorthair',\n",
       "   'Egyptian_Mau',\n",
       "   'Maine_Coon',\n",
       "   'Persian',\n",
       "   'Ragdoll',\n",
       "   'Russian_Blue',\n",
       "   'Siamese',\n",
       "   'Sphynx',\n",
       "   'american_bulldog',\n",
       "   'american_pit_bull_terrier',\n",
       "   'basset_hound',\n",
       "   'beagle',\n",
       "   'boxer',\n",
       "   'chihuahua',\n",
       "   'english_cocker_spaniel',\n",
       "   'english_setter',\n",
       "   'german_shorthaired',\n",
       "   'great_pyrenees',\n",
       "   'havanese',\n",
       "   'japanese_chin',\n",
       "   'keeshond',\n",
       "   'leonberger',\n",
       "   'miniature_pinscher',\n",
       "   'newfoundland',\n",
       "   'pomeranian',\n",
       "   'pug',\n",
       "   'saint_bernard',\n",
       "   'samoyed',\n",
       "   'scottish_terrier',\n",
       "   'shiba_inu',\n",
       "   'staffordshire_bull_terrier',\n",
       "   'wheaten_terrier',\n",
       "   'yorkshire_terrier']}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['tfms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the `item` transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomResizedCrop': {'min_scale': 0.75,\n",
       "  'ratio': (1.0, 1.0),\n",
       "  'size': (460, 460),\n",
       "  'val_xtra': 0.14},\n",
       " 'ToTensor': True}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['after_item']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally our batch transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IntToFloatTensor': {'div': 255.0, 'div_mask': 1},\n",
       " 'Normalize': {'axes': (0, 2, 3), 'mean': array([[[[0.485]],\n",
       "  \n",
       "          [[0.456]],\n",
       "  \n",
       "          [[0.406]]]], dtype=float32), 'std': array([[[[0.229]],\n",
       "  \n",
       "          [[0.224]],\n",
       "  \n",
       "          [[0.225]]]], dtype=float32)}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['after_batch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular\n",
    "\n",
    "Next we'll look at a tabular example. We will use the `ADULT_SAMPLE` dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'adult.csv')\n",
    "splits = RandomSplitter()(range_of(df))\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, splits=splits)\n",
    "dls = to.dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def _extract_tfm_dicts(dl:TabDataLoader):\n",
    "    \"Extracts all transform params from `dl`\"\n",
    "    types = 'normalize,fill_missing,categorify'\n",
    "    if hasattr(dl, 'categorize'): types += ',categorize'\n",
    "    if hasattr(dl, 'regression_setup'): types += ',regression_setup'\n",
    "    tfms = {}\n",
    "    for t in types.split(','):\n",
    "        tfm = getattr(dl, t)\n",
    "        tfms[t] = to_list(attrdict(tfm, *tfm.store_attrs.split(',')))\n",
    "    return tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage is the exact same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_dicts = get_information(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(tfm_dicts),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However our keys are different. By default it will have `normalize`, `fill_missing`, and `categorify`, and then depending on what is available it will store either `categorize` or `regression_setup` to tell us about our outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example from `normalize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'means': {'age': 38.61818112019655,\n",
       "  'education-num': 10.08330454144113,\n",
       "  'fnlwgt': 189097.24162155937},\n",
       " 'stds': {'age': 13.65958366512057,\n",
       "  'education-num': 2.5547649904806056,\n",
       "  'fnlwgt': 105240.85724028994}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['normalize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fill_missing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add_col': True,\n",
       " 'fill_strategy': 'median',\n",
       " 'fill_vals': {'education-num': 0},\n",
       " 'na_dict': {'education-num': 10.0}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['fill_missing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `categorify`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'education': ['#na#',\n",
       "   ' 10th',\n",
       "   ' 11th',\n",
       "   ' 12th',\n",
       "   ' 1st-4th',\n",
       "   ' 5th-6th',\n",
       "   ' 7th-8th',\n",
       "   ' 9th',\n",
       "   ' Assoc-acdm',\n",
       "   ' Assoc-voc',\n",
       "   ' Bachelors',\n",
       "   ' Doctorate',\n",
       "   ' HS-grad',\n",
       "   ' Masters',\n",
       "   ' Preschool',\n",
       "   ' Prof-school',\n",
       "   ' Some-college'],\n",
       "  'education-num_na': ['#na#', False, True],\n",
       "  'marital-status': ['#na#',\n",
       "   ' Divorced',\n",
       "   ' Married-AF-spouse',\n",
       "   ' Married-civ-spouse',\n",
       "   ' Married-spouse-absent',\n",
       "   ' Never-married',\n",
       "   ' Separated',\n",
       "   ' Widowed'],\n",
       "  'occupation': ['#na#',\n",
       "   ' ?',\n",
       "   ' Adm-clerical',\n",
       "   ' Armed-Forces',\n",
       "   ' Craft-repair',\n",
       "   ' Exec-managerial',\n",
       "   ' Farming-fishing',\n",
       "   ' Handlers-cleaners',\n",
       "   ' Machine-op-inspct',\n",
       "   ' Other-service',\n",
       "   ' Priv-house-serv',\n",
       "   ' Prof-specialty',\n",
       "   ' Protective-serv',\n",
       "   ' Sales',\n",
       "   ' Tech-support',\n",
       "   ' Transport-moving'],\n",
       "  'race': ['#na#',\n",
       "   ' Amer-Indian-Eskimo',\n",
       "   ' Asian-Pac-Islander',\n",
       "   ' Black',\n",
       "   ' Other',\n",
       "   ' White'],\n",
       "  'relationship': ['#na#',\n",
       "   ' Husband',\n",
       "   ' Not-in-family',\n",
       "   ' Other-relative',\n",
       "   ' Own-child',\n",
       "   ' Unmarried',\n",
       "   ' Wife'],\n",
       "  'workclass': ['#na#',\n",
       "   ' ?',\n",
       "   ' Federal-gov',\n",
       "   ' Local-gov',\n",
       "   ' Never-worked',\n",
       "   ' Private',\n",
       "   ' Self-emp-inc',\n",
       "   ' Self-emp-not-inc',\n",
       "   ' State-gov',\n",
       "   ' Without-pay']}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['categorify']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finally `categorize` (since we have a classification problem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add_na': False, 'vocab': ['<50k', '>=50k']}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['categorize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To export, a new `to_fastinference` function has been made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def to_fastinference(x:Learner, data_fname='data', model_fname='model', path=Path('.')):\n",
    "    \"Export data for `fastinference_onnx` or `_pytorch` to use\"\n",
    "    dicts = get_information(x.dls)\n",
    "    with open(path/f'{data_fname}.pkl', 'wb') as handle:\n",
    "        pickle.dump(procs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    x._end_cleanup()\n",
    "    state = x.opt.state_dict() if x.opt is not None else None\n",
    "    x.opt = None\n",
    "    torch.save(x.model.state_dict(), path/f'{model_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner.to_fastinference(x:fastai2.learner.Learner, data_fname='data', model_fname='model', path=Path('.'))\n",
      "Export data for `fastinference_onnx` or `_pytorch` to use\n",
      "\n",
      "To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev\n"
     ]
    }
   ],
   "source": [
    "doc(Learner.to_fastinference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params:\n",
    "\n",
    "* `data_fname`: Filename to save our extracted `DataLoader` information, default is `data`\n",
    "* `model_fname`: Filename to save our current model, default is `model`\n",
    "* `path`: Path to save our model and data to, default is `.`\n",
    "\n",
    "Exported files will have the extension `.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, layers=[200,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply call `learn.to_fastinference` and it will export everything needed for `fastinference_pytorch` or `fastinference_onnx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fastinference(data_fname = 'data', model_fname = 'model', path = Path('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\"\"\"\n",
    "# TODO: Text\n",
    "Things to save:\n",
    "\n",
    "\n",
    "* `data.vocab`\n",
    "* `data.o2i`\n",
    "* Tokenizer\n",
    "* All the rules in `text.core`:\n",
    "[<function fastai2.text.core.fix_html>,\n",
    " <function fastai2.text.core.replace_rep>,\n",
    " <function fastai2.text.core.replace_wrep>,\n",
    " <function fastai2.text.core.spec_add_spaces>,\n",
    " <function fastai2.text.core.rm_useless_spaces>,\n",
    " <function fastai2.text.core.replace_all_caps>,\n",
    " <function fastai2.text.core.replace_maj>,\n",
    " <function fastai2.text.core.lowercase>]\n",
    "\n",
    "- Ensure that `L` is in the library\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
