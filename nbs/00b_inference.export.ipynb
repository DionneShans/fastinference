{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp inference.export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference.export\n",
    "> This module contains the main functionality for extracting the transform parameters from DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example we will look at the pets dataset. We will define a series of transforms in our Pipelines, and we will attempt to extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "fnames = get_image_files(path/'images')\n",
    "pat = r'(.+)_\\d+.jpg$'\n",
    "batch_tfms = [*aug_transforms(), Normalize.from_stats(*imagenet_stats)]\n",
    "item_tfms = RandomResizedCrop(460, min_scale=0.75, ratio=(1.,1.))\n",
    "bs=64\n",
    "dls = ImageDataLoaders.from_name_re(path, fnames, pat, batch_tfms=batch_tfms, \n",
    "                                   item_tfms=item_tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell\n",
    "def to_list(b):\n",
    "    \"Recursively make any `L()` or CategoryMap to list\"\n",
    "    def _inner(o): \n",
    "        if isinstance(o,L) or isinstance(o, CategoryMap):\n",
    "            return list(o)\n",
    "        elif isinstance(o, Tensor):\n",
    "            return np.array(to_detach(o))\n",
    "        else: return o\n",
    "    for k in b.keys():\n",
    "        b[k] = apply(_inner,b[k])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _gen_dict(tfm):\n",
    "    \"Grabs the `attrdict` and transform name from `tfm`\"\n",
    "    tfm_dict = attrdict(tfm, *tfm.store_attrs.split(','))\n",
    "    if 'partial' in tfm.name:\n",
    "        tfm_name = tfm.name[1].split(' --')[0]\n",
    "    else:\n",
    "        tfm_name = tfm.name.split(' --')[0]\n",
    "    return tfm_dict, tfm_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_tfm_dict(tfms, type_tfm=False):\n",
    "    \"Extracts transform params from `tfms`\"\n",
    "    tfm_dicts = {}\n",
    "    for tfm in tfms:\n",
    "        if hasattr(tfm, 'store_attrs') and not isinstance(tfm, AffineCoordTfm):\n",
    "            if type_tfm or tfm.split_idx is not 0:\n",
    "                tfm_dict,name = _gen_dict(tfm)\n",
    "                tfm_dict = to_list(tfm_dict)\n",
    "                tfm_dicts[name] = tfm_dict\n",
    "    return tfm_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_lighting': 0.2,\n",
       " 'p': 0.75,\n",
       " 'draw': None,\n",
       " 'batch': False,\n",
       " 'change': tensor([1.0732], device='cuda:0')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.after_batch[2].fs[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomResizedCrop': {'size': (460, 460),\n",
       "  'min_scale': 0.75,\n",
       "  'ratio': (1.0, 1.0),\n",
       "  'val_xtra': 0.14}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_make_tfm_dict(dls.after_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_lighting': 0.2,\n",
       " 'p': 0.75,\n",
       " 'draw': None,\n",
       " 'batch': False,\n",
       " 'change': tensor([1.0732], device='cuda:0')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.after_batch[2].fs[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_d = dls.after_batch[2].fs[0].__dict__.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_lighting': 0.2,\n",
       " 'p': 0.75,\n",
       " 'draw': None,\n",
       " 'batch': False,\n",
       " 'change': TensorImage([0.5723], device='cuda:0')}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_d.pop('change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.augment import _BrightnessLogit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandTransform??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [<fastai2.vision.augment._BrightnessLogit object at 0x7f77c6232f90>,<fastai2.vision.augment._ContrastLogit object at 0x7f77c6232e90>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_logits(tfm):\n",
    "    name = tfm.__class__.name\n",
    "    t_d = tfm.__dict__\n",
    "    t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_BrightnessLogit'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.after_batch[2].fs[0].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "ab_dict = {}\n",
    "for tfm in dls.after_batch:\n",
    "    if isinstance(tfm, AffineCoordTfm) or isinstance(tfm, LightingTfm):\n",
    "        if hasattr(tfm, 'aff_fs'):\n",
    "            for t in tfm.aff_fs:\n",
    "                ab_dict[t.func.__name__] = t.keywords\n",
    "        elif hasattr(tfm, 'coord_fs'):\n",
    "            for t in tfm.coord_fs:\n",
    "                t_d,n = _gen_dict(t)\n",
    "                ab_dict[n] = t_d\n",
    "        elif hasattr(tfm, 'fs'):\n",
    "            for t in tfm.fs:\n",
    "                t_d,n = _gen_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(_make_tfm_dict(dls.tfms, True)), 1)\n",
    "ab_dict = _make_tfm_dict(dls.after_batch)\n",
    "in_('Normalize', ab_dict.keys());\n",
    "not in_('Flip', ab_dict.keys());\n",
    "it_dict = _make_tfm_dict(dls.after_item)\n",
    "in_('RandomResizedCrop', ab_dict.keys())\n",
    "not in_('ToTensor', ab_dict.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def _extract_tfm_dicts(dl:TfmdDL):\n",
    "    \"Extracts all transform params from `dl`\"\n",
    "    type_tfm,use_images = True,False\n",
    "    attrs = ['tfms','after_item','after_batch']\n",
    "    tfm_dicts = {}\n",
    "    for attr in attrs:\n",
    "        tfm_dicts[attr] = _make_tfm_dict(getattr(dl, attr), type_tfm)\n",
    "        if attr == 'tfms': \n",
    "            if getattr(dl,attr)[0][1].name == 'PILBase.create':\n",
    "                use_images=True\n",
    "        if attr == 'after_item': tfm_dicts[attr]['ToTensor'] = {'is_image':use_images}\n",
    "        type_tfm = False\n",
    "    return tfm_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_information(dls): return _extract_tfm_dicts(dls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_information\n",
    "\n",
    "This function will take any set of `DataLoaders` and extract the transforms which are important during inference and their information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_info = get_information(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(tfm_info),3)\n",
    "test_eq(tfm_info.keys(), ['tfms','after_item','after_batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vision it will contain `tfms`, `after_item`, and `after_batch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, our `type` transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categorize': {'vocab': ['Abyssinian',\n",
       "   'Bengal',\n",
       "   'Birman',\n",
       "   'Bombay',\n",
       "   'British_Shorthair',\n",
       "   'Egyptian_Mau',\n",
       "   'Maine_Coon',\n",
       "   'Persian',\n",
       "   'Ragdoll',\n",
       "   'Russian_Blue',\n",
       "   'Siamese',\n",
       "   'Sphynx',\n",
       "   'american_bulldog',\n",
       "   'american_pit_bull_terrier',\n",
       "   'basset_hound',\n",
       "   'beagle',\n",
       "   'boxer',\n",
       "   'chihuahua',\n",
       "   'english_cocker_spaniel',\n",
       "   'english_setter',\n",
       "   'german_shorthaired',\n",
       "   'great_pyrenees',\n",
       "   'havanese',\n",
       "   'japanese_chin',\n",
       "   'keeshond',\n",
       "   'leonberger',\n",
       "   'miniature_pinscher',\n",
       "   'newfoundland',\n",
       "   'pomeranian',\n",
       "   'pug',\n",
       "   'saint_bernard',\n",
       "   'samoyed',\n",
       "   'scottish_terrier',\n",
       "   'shiba_inu',\n",
       "   'staffordshire_bull_terrier',\n",
       "   'wheaten_terrier',\n",
       "   'yorkshire_terrier'],\n",
       "  'add_na': False}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['tfms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the `item` transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomResizedCrop': {'size': (460, 460),\n",
       "  'min_scale': 0.75,\n",
       "  'ratio': (1.0, 1.0),\n",
       "  'val_xtra': 0.14},\n",
       " 'ToTensor': {'is_image': True}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['after_item']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally our batch transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IntToFloatTensor': {'div': 255.0, 'div_mask': 1},\n",
       " 'Normalize': {'mean': array([[[[0.485]],\n",
       "  \n",
       "          [[0.456]],\n",
       "  \n",
       "          [[0.406]]]], dtype=float32),\n",
       "  'std': array([[[[0.229]],\n",
       "  \n",
       "          [[0.224]],\n",
       "  \n",
       "          [[0.225]]]], dtype=float32),\n",
       "  'axes': (0, 2, 3)}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['after_batch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular\n",
    "\n",
    "Next we'll look at a tabular example. We will use the `ADULT_SAMPLE` dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'adult.csv')\n",
    "splits = RandomSplitter()(range_of(df))\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, splits=splits)\n",
    "dls = to.dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normalize -- {'means': {'age': 38.52497216783754, 'fnlwgt': 189756.69177319668, 'education-num': 10.091481438826827}, 'stds': {'age': 13.633111349975714, 'fnlwgt': 105165.09125395071, 'education-num': 2.5544176335877404}}:\n",
       "(Tabular,object) -> encodes\n",
       "(TensorImage,object) -> encodes\n",
       " (Tabular,object) -> decodes\n",
       "(TensorImage,object) -> decodes"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def _extract_tfm_dicts(dl:TabDataLoader):\n",
    "    \"Extracts all transform params from `dl`\"\n",
    "    types = 'normalize,fill_missing,categorify'\n",
    "    if hasattr(dl, 'categorize'): types += ',categorize'\n",
    "    if hasattr(dl, 'regression_setup'): types += ',regression_setup'\n",
    "    tfms = {}\n",
    "    name2idx = {name:n for n,name in enumerate(dl.dataset) if name in dl.cat_names or name in dl.cont_names}\n",
    "    idx2name = {v:k for k,v in name2idx.items()}\n",
    "    cat_idxs = {name2idx[name]:name for name in cat_names}\n",
    "    cont_idxs = {name2idx[name]:name for name in cont_names}\n",
    "    names = {'cats':cat_idxs, 'conts':cont_idxs}\n",
    "    tfms['encoder'] = names\n",
    "    for t in types.split(','):\n",
    "        tfm = getattr(dl, t)\n",
    "        tfms[t] = to_list(attrdict(tfm, *tfm.store_attrs.split(',')))\n",
    "    \n",
    "    categorize = dl.procs.categorify.classes.copy()\n",
    "    for i,c in enumerate(categorize):\n",
    "        categorize[c] = {a:b for a,b in enumerate(categorize[c])}\n",
    "        categorize[c] = {v: k for k, v in categorize[c].items()}\n",
    "        categorize[c].pop('#na#')\n",
    "        categorize[c][np.nan] = 0\n",
    "    tfms['categorify']['classes'] = categorize\n",
    "    new_dict = {}\n",
    "    for k,v in tfms.items(): \n",
    "        if k == 'fill_missing': \n",
    "            k = 'FillMissing'\n",
    "            new_dict.update({k:v})\n",
    "        else: \n",
    "            new_dict.update({k.capitalize():v})\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage is the exact same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_dicts = get_information(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(tfm_dicts),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However our keys are different. By default it will have `normalize`, `fill_missing`, and `categorify`, and then depending on what is available it will store either `categorize` or `regression_setup` to tell us about our outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example from `Normalize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'means': {'age': 38.579446427885905,\n",
       "  'fnlwgt': 189089.21129409957,\n",
       "  'education-num': 10.079273676532688},\n",
       " 'stds': {'age': 13.668500198858403,\n",
       "  'fnlwgt': 105206.02215862622,\n",
       "  'education-num': 2.5518035837225304}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['Normalize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FillMissing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fill_strategy': 'median',\n",
       " 'add_col': True,\n",
       " 'fill_vals': {'education-num': 0},\n",
       " 'na_dict': {'education-num': 10.0}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['FillMissing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `Categorify`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'education-num_na'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['Categorify']['classes'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finally `categorize` (since we have a classification problem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab': ['<50k', '>=50k'], 'add_na': False}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['Categorize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To export, a new `to_fastinference` function has been made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def to_fastinference(x:Learner, data_fname='data', model_fname='model', path=Path('.')):\n",
    "    \"Export data for `fastinference_onnx` or `_pytorch` to use\"\n",
    "    if not isinstance(path,Path): path = Path(path)\n",
    "    dicts = get_information(x.dls)\n",
    "    with open(path/f'{data_fname}.pkl', 'wb') as handle:\n",
    "        pickle.dump(dicts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    torch.save(x.model, path/f'{model_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(Learner.to_fastinference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params:\n",
    "\n",
    "* `data_fname`: Filename to save our extracted `DataLoader` information, default is `data`\n",
    "* `model_fname`: Filename to save our current model, default is `model`\n",
    "* `path`: Path to save our model and data to, default is `.`\n",
    "\n",
    "Exported files will have the extension `.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, [200,100], metrics=[accuracy])\n",
    "learn.to_fastinference(path='../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply call `learn.to_fastinference` and it will export everything needed for `fastinference_pytorch` or `fastinference_onnx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fastinference(data_fname = 'data', model_fname = 'model', path = Path('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\"\"\"\n",
    "# TODO: Text\n",
    "Things to save:\n",
    "\n",
    "\n",
    "* `data.vocab`\n",
    "* `data.o2i`\n",
    "* Tokenizer\n",
    "* All the rules in `text.core`:\n",
    "[<function fastai2.text.core.fix_html>,\n",
    " <function fastai2.text.core.replace_rep>,\n",
    " <function fastai2.text.core.replace_wrep>,\n",
    " <function fastai2.text.core.spec_add_spaces>,\n",
    " <function fastai2.text.core.rm_useless_spaces>,\n",
    " <function fastai2.text.core.replace_all_caps>,\n",
    " <function fastai2.text.core.replace_maj>,\n",
    " <function fastai2.text.core.lowercase>]\n",
    "\n",
    "- Ensure that `L` is in the library\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
