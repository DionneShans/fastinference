{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp inference.export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference.export\n",
    "> This module contains the main functionality for extracting the transform parameters from DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example we will look at the pets dataset. We will define a series of transforms in our Pipelines, and we will attempt to extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "fnames = get_image_files(path/'images')\n",
    "pat = r'(.+)_\\d+.jpg$'\n",
    "batch_tfms = [*aug_transforms(size=224, max_warp=0.8), Normalize.from_stats(*imagenet_stats)]\n",
    "item_tfms = RandomResizedCrop(460, min_scale=0.75, ratio=(1.,1.))\n",
    "bs=64\n",
    "dls = ImageDataLoaders.from_name_re(path, fnames, pat, batch_tfms=batch_tfms, \n",
    "                                   item_tfms=item_tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _gen_dict(tfm):\n",
    "    \"Grabs the `attrdict` and transform name from `tfm`\"\n",
    "    tfm_dict = attrdict(tfm, *tfm.store_attrs.split(','))\n",
    "    if 'partial' in tfm.name:\n",
    "        tfm_name = tfm.name[1].split(' --')[0]\n",
    "    else:\n",
    "        tfm_name = tfm.name.split(' --')[0]\n",
    "    return tfm_dict, tfm_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: partial -> Categorize -- {'vocab': (#37) ['Abyssinian','Bengal','Birman','Bombay','British_Shorthair','Egyptian_Mau','Maine_Coon','Persian','Ragdoll','Russian_Blue'...], 'add_na': False}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.tfms[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_tfm_dict(tfms, type_tfm=False):\n",
    "    \"Extracts transform params from `tfms`\"\n",
    "    tfm_dicts = {}\n",
    "    for tfm in tfms:\n",
    "        if hasattr(tfm, 'store_attrs') and not isinstance(tfm, AffineCoordTfm):\n",
    "            if type_tfm or tfm.split_idx is not 0:\n",
    "                tfm_dict,name = _gen_dict(tfm)\n",
    "                tfm_dicts[name] = tfm_dict\n",
    "    return tfm_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(_make_tfm_dict(dls.tfms, True)), 1)\n",
    "ab_dict = _make_tfm_dict(dls.after_batch)\n",
    "in_('Normalize', ab_dict.keys());\n",
    "not in_('Flip', ab_dict.keys());\n",
    "it_dict = _make_tfm_dict(dls.after_item)\n",
    "in_('RnadomResizedCrop', ab_dict.keys())\n",
    "not in_('ToTensor', ab_dict.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def _extract_tfm_dicts(dl:TfmdDL):\n",
    "    \"Extracts all transform params from `dl`\"\n",
    "    type_tfm = True\n",
    "    attrs = ['tfms','after_item','after_batch']\n",
    "    tfm_dicts = {}\n",
    "    for attr in attrs:\n",
    "        tfm_dicts[attr] = _make_tfm_dict(getattr(dl, attr), type_tfm)\n",
    "        type_tfm = False\n",
    "    return tfm_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_information(dls): return _extract_tfm_dicts(dls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_information\n",
    "\n",
    "This function will take any set of `DataLoaders` and extract the transforms which are important during inference and their information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_info = get_information(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(tfm_info),3)\n",
    "test_eq(tfm_info.keys(), ['tfms','after_item','after_batch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vision it will contain `tfms`, `after_item`, and `after_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categorize': {'add_na': False,\n",
       "  'vocab': (#37) ['Abyssinian','Bengal','Birman','Bombay','British_Shorthair','Egyptian_Mau','Maine_Coon','Persian','Ragdoll','Russian_Blue'...]}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['tfms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here are the type transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomResizedCrop': {'min_scale': 0.75,\n",
       "  'ratio': (1.0, 1.0),\n",
       "  'size': (460, 460),\n",
       "  'val_xtra': 0.14}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['after_item']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The item transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IntToFloatTensor': {'div': 255.0, 'div_mask': 1},\n",
       " 'Normalize': {'axes': (0, 2, 3), 'mean': tensor([[[[0.4850]],\n",
       "  \n",
       "           [[0.4560]],\n",
       "  \n",
       "           [[0.4060]]]], device='cuda:0'), 'std': tensor([[[[0.2290]],\n",
       "  \n",
       "           [[0.2240]],\n",
       "  \n",
       "           [[0.2250]]]], device='cuda:0')}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_info['after_batch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our batch transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular\n",
    "\n",
    "Next we'll look at a tabular example. We will use the `ADULT_SAMPLE` dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'adult.csv')\n",
    "splits = RandomSplitter()(range_of(df))\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, splits=splits)\n",
    "dls = to.dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def _extract_tfm_dicts(dl:TabDataLoader):\n",
    "    \"Extracts all transform params from `dl`\"\n",
    "    types = 'normalize,fill_missing,categorify'\n",
    "    if hasattr(dl, 'categorize'): types += ',categorize'\n",
    "    if hasattr(dl, 'regression_setup'): types += ',regression_setup'\n",
    "    tfms = {}\n",
    "    for t in types.split(','):\n",
    "        tfm = getattr(dl, t)\n",
    "        tfms[t] = attrdict(tfm, *tfm.store_attrs.split(','))\n",
    "    return tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage is the exact same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_dicts = get_information(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(tfm_dicts),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However our keys are different. By default it will have `normalize`, `fill_missing`, and `categorify`, and then depending on what is available it will store either `categorize` or `regression_setup` to tell us about our outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example from `normalize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'means': {'age': 38.54896541134017,\n",
       "  'education-num': 10.086989903643135,\n",
       "  'fnlwgt': 189806.53975200583},\n",
       " 'stds': {'age': 13.61623631055053,\n",
       "  'education-num': 2.5541612422904,\n",
       "  'fnlwgt': 105132.50000965082}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['normalize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fill_missing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add_col': True,\n",
       " 'fill_strategy': 'median',\n",
       " 'fill_vals': defaultdict(int, {'education-num': 0}),\n",
       " 'na_dict': {'education-num': 10.0}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['fill_missing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `categorify`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': {'education': (#17) ['#na#',' 10th',' 11th',' 12th',' 1st-4th',' 5th-6th',' 7th-8th',' 9th',' Assoc-acdm',' Assoc-voc'...],\n",
       "  'education-num_na': (#3) ['#na#',False,True],\n",
       "  'marital-status': (#8) ['#na#',' Divorced',' Married-AF-spouse',' Married-civ-spouse',' Married-spouse-absent',' Never-married',' Separated',' Widowed'],\n",
       "  'occupation': (#16) ['#na#',' ?',' Adm-clerical',' Armed-Forces',' Craft-repair',' Exec-managerial',' Farming-fishing',' Handlers-cleaners',' Machine-op-inspct',' Other-service'...],\n",
       "  'race': (#6) ['#na#',' Amer-Indian-Eskimo',' Asian-Pac-Islander',' Black',' Other',' White'],\n",
       "  'relationship': (#7) ['#na#',' Husband',' Not-in-family',' Other-relative',' Own-child',' Unmarried',' Wife'],\n",
       "  'workclass': (#10) ['#na#',' ?',' Federal-gov',' Local-gov',' Never-worked',' Private',' Self-emp-inc',' Self-emp-not-inc',' State-gov',' Without-pay']}}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['categorify']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finally `categorize` (since we have a classification problem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add_na': False, 'vocab': (#2) ['<50k','>=50k']}"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_dicts['categorize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To export, a new `to_fastinference` function has been made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner.to_fastinference(x:fastai2.learner.Learner, data_fname='data', model_fname='model', path=Path('.'))\n",
      "Export data for `fastinference_onnx` or `_pytorch` to use\n",
      "\n",
      "To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev\n"
     ]
    }
   ],
   "source": [
    "doc(Learner.to_fastinference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params:\n",
    "\n",
    "* `data_fname`: Filename to save our extracted `DataLoader` information, default is `data`\n",
    "* `model_fname`: Filename to save our current model, default is `model`\n",
    "* `path`: Path to save our model and data to, default is `.`\n",
    "\n",
    "Exported files will have the extension `.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def to_fastinference(x:Learner, data_fname='data', model_fname='model', path=Path('.')):\n",
    "    \"Export data for `fastinference_onnx` or `_pytorch` to use\"\n",
    "    dicts = get_information(x.dls)\n",
    "    with open(path/f'{data_fname}.pkl', 'wb') as handle:\n",
    "        pickle.dump(procs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    x._end_cleanup()\n",
    "    state = x.opt.state_dict() if x.opt is not None else None\n",
    "    x.opt = None\n",
    "    torch.save(x.model.state_dict(), path/f'{model_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, layers=[200,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply call `learn.to_fastinference` and it will export everything needed for `fastinference_pytorch` or `fastinference_onnx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_fastinference(data_fname = 'data', model_fname = 'model', path = Path('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\"\"\"\n",
    "# TODO: Text\n",
    "Things to save:\n",
    "\n",
    "\n",
    "* `data.vocab`\n",
    "* `data.o2i`\n",
    "* Tokenizer\n",
    "* All the rules in `text.core`:\n",
    "[<function fastai2.text.core.fix_html>,\n",
    " <function fastai2.text.core.replace_rep>,\n",
    " <function fastai2.text.core.replace_wrep>,\n",
    " <function fastai2.text.core.spec_add_spaces>,\n",
    " <function fastai2.text.core.rm_useless_spaces>,\n",
    " <function fastai2.text.core.replace_all_caps>,\n",
    " <function fastai2.text.core.replace_maj>,\n",
    " <function fastai2.text.core.lowercase>]\n",
    "\n",
    "- Ensure that `L` is in the library\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
