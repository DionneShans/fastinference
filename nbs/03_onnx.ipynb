{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_onnx\n",
    "> Exporting models to `ONNX` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai2.tabular.all import *\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def to_onnx(x:Learner, fname='export.onnx'):\n",
    "    \"Export model to `ONNX` format\"\n",
    "    orig_bs = x.dls[0].bs\n",
    "    x.dls[0].bs=1\n",
    "    dummy_inp = next(iter(x.dls[0]))\n",
    "    names = inspect.getfullargspec(x.model.forward).args[1:]\n",
    "    torch.onnx.export(x.model, dummy_inp[:-1], fname,\n",
    "                     input_names=names, output_names=['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently supports single-output models. See an example usage below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of(df))\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, y_block=y_block, splits=splits).dataloaders()\n",
    "learn = tabular_learner(dls, layers=[200,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_onnx('tabular.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fastONNX():\n",
    "    \"Onnx wrapper for `predict`\"\n",
    "    def __init__(self, fn):\n",
    "        self.ort_session = ort.InferenceSession(fn)\n",
    "        try:\n",
    "            self.ort_session.set_providers(['CUDAExecutionProvider'])\n",
    "        except:\n",
    "            self.ort_session.set_providers(['CPUExecutionProvider'])\n",
    "            \n",
    "    def predict(self, *inp):\n",
    "        names = [i.name for i in self.ort_session.get_inputs()]\n",
    "        inps = [x.cpu().numpy() for x in inp]\n",
    "        xs = {name:x for name,x in zip(names,inps)}\n",
    "        outs = self.ort_session.run(None, xs)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_inf = fastONNX('tabular.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(learn.dls[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 µs ± 287 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = tab_inf.predict(*batch[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 µs ± 291 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    learn.model.eval()\n",
    "    out = learn.model(*batch[:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
