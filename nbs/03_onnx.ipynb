{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_onnx\n",
    "> Exporting models to `ONNX` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai2.tabular.all import *\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def to_onnx(x:Learner, fname='export', path=Path('.')):\n",
    "    \"Export model to `ONNX` format\"\n",
    "    orig_bs = x.dls[0].bs\n",
    "    x.dls[0].bs=1\n",
    "    dummy_inp = next(iter(x.dls[0]))\n",
    "    x.dls[0].bs = orig_bs\n",
    "    names = inspect.getfullargspec(x.model.forward).args[1:]\n",
    "    dynamic_axes = {n:{0:'batch_size'} for n in names}\n",
    "    dynamic_axes['output'] = {0:'batch_size'}\n",
    "    torch.onnx.export(x.model, dummy_inp[:-1], path/f'{fname}.onnx',\n",
    "                     input_names=names, output_names=['output'],\n",
    "                     dynamic_axes=dynamic_axes)\n",
    "    x.export(path/f'{fname}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently supports single-output models. See an example usage below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of(df))\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "y_names = 'salary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularPandas(df, procs=procs, cat_names=cat_names, cont_names=cont_names,\n",
    "                   y_names=y_names, splits=splits).dataloaders()\n",
    "learn = tabular_learner(dls, layers=[200,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.to_onnx('tabular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mldata/fastai2/zach/fastinference\n",
      "/media/mldata/fastai2/zach/fastinference/nbs\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from fastinference.inference import _fully_decode, _decode_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class fastONNX():\n",
    "    \"ONNX wrapper for `Learner`\"\n",
    "    def __init__(self, fn):\n",
    "        self.ort_session = ort.InferenceSession(fn+'.onnx')\n",
    "        try:\n",
    "            self.ort_session.set_providers(['CUDAExecutionProvider'])\n",
    "            cpu = False\n",
    "        except:\n",
    "            self.ort_session.set_providers(['CPUExecutionProvider'])\n",
    "            cpu = True\n",
    "        self.learn = load_learner(fn+'.pkl')\n",
    "        self.learn.model = None\n",
    "    \n",
    "    def to_numpy(self, t:tensor): return t.detach.cpu().numpy() if t.requires_grad else t.cpu().numpy()\n",
    "    \n",
    "    def predict(self, inps):\n",
    "        \"Predict a single numpy item\"\n",
    "        if isinstance(inps[0], Tensor): inps = [self.to_numpy(x) for x in inps]\n",
    "        names = [i.name for i in self.ort_session.get_inputs()]\n",
    "        xs = {name:x for name,x in zip(names,inps)}\n",
    "        outs = self.ort_session.run(None, xs)\n",
    "        return outs\n",
    "    \n",
    "    def get_preds(self, dl=None, raw_outs=False, decoded_loss=True, fully_decoded=False):\n",
    "        \"Get predictions with possible decoding\"\n",
    "        inps, outs, dec_out, raw = [], [], [], []\n",
    "        loss_func = self.learn.loss_func\n",
    "        is_multi, n_inp = False, self.learn.dls.n_inp\n",
    "        if n_inp > 1:\n",
    "            is_multi = true\n",
    "            [inps.append([]) for _ in range(n_inp)]\n",
    "        for batch in dl:\n",
    "            batch_np = []\n",
    "            if is_multi:\n",
    "                for i in range(n_inp):\n",
    "                    item = self.to_numpy(batch[i])\n",
    "                    inps[i].append(item)\n",
    "                    batch_np.append(item)\n",
    "            else:\n",
    "                inps.append(self.to_numpy(batch[:n_inp]))\n",
    "            if decoded_loss or fully_decoded:\n",
    "                out = self.predict(batch_np)\n",
    "                raw.append(out)\n",
    "                dec_out.append(loss_func.decodes(tensor(out)))\n",
    "            else:\n",
    "                raw.append(self.predict(batch_np))\n",
    "        axis = 1 if len(dl) > 1 else 0\n",
    "        raw = np.concatenate(raw, axis=axis)\n",
    "        if decoded_loss or fully_decoded:\n",
    "            dec_out = np.concatenate(dec_out, axis=axis)\n",
    "        if not raw_outs:\n",
    "            try: outs.insert(0, loss_func.activation(tensor(raw)).numpy())\n",
    "            except: outs.insert(0, dec_out)\n",
    "        else:\n",
    "            outs.insert(0, raw)\n",
    "        if fully_decoded: outs = _fully_decode(self.learn.dls, inps, outs, dec_out, is_multi)\n",
    "        if decoded_loss: outs = _decode_loss(self.learn.dls.vocab, dec_out, outs)\n",
    "        return outs\n",
    "    \n",
    "    def test_dl(self, test_items, **kwargs): return self.learn.dls.test_dl(test_items, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = learn.dls.test_dl(df.iloc[:100], bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_inf = fastONNX('tabular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.11 ms, sys: 207 µs, total: 9.32 ms\n",
      "Wall time: 8.59 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = tab_inf.get_preds(dl=dl, raw_outs=False, decoded_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.85 ms, sys: 738 µs, total: 4.59 ms\n",
      "Wall time: 2.22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = tab_inf.predict(batch[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
