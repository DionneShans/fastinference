{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tabular.core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tabular.core\n",
    "> This module contains helper functions for using in various interpretation classes for Pavel's interpretation modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pickle import load, dump\n",
    "from bz2 import BZ2File\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _merge_tfms(means, stds):\n",
    "    \"merge mean and std to singular dictionary\"\n",
    "    names = means.keys()\n",
    "    merged = {}\n",
    "    for n in names:\n",
    "        mean, std = means[n], stds[n]\n",
    "        merged[n] = {'mean':mean, 'std':std}\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_procs(dls):\n",
    "    \"Extract tabular `procs` from `dls` and get indicies of `NumPy`\"\n",
    "    fm = dls.procs.fill_missing\n",
    "    na_dict = getattr(fm, 'na_dict')\n",
    "    add_col = getattr(fm, 'add_col')\n",
    "    fm = {'na_dict':na_dict, 'add_col':add_col}\n",
    "\n",
    "    norm = dls.procs.normalize\n",
    "    means = getattr(norm, 'means').to_dict()\n",
    "    stds = getattr(norm, 'stds').to_dict()\n",
    "    norm = _merge_tfms(means, stds)\n",
    "    \n",
    "    cat_names = dls.cat_names\n",
    "    cont_names = dls.cont_names\n",
    "    \n",
    "    name2idx = {name:n for n,name in enumerate(dls.dataset) if name in cat_names or name in cont_names}\n",
    "    idx2name = {v: k for k, v in name2idx.items()}\n",
    "    \n",
    "    cat_idxs = {name2idx[name]:name for name in cat_names}\n",
    "    cont_idxs = {name2idx[name]:name for name in cont_names}\n",
    "    names = {'cats':cat_idxs, 'conts':cont_idxs}\n",
    "    \n",
    "    categorize = dls.procs.categorify.classes.copy()\n",
    "    for i,c in enumerate(categorize):\n",
    "        categorize[c] = {a:b for a,b in enumerate(categorize[c])}\n",
    "        categorize[c] = {v: k for k, v in categorize[c].items()}\n",
    "        categorize[c].pop('#na#')\n",
    "        categorize[c][np.nan] = 0\n",
    "    return {'FillMissing':fm, 'Normalize':norm, 'Categorize':categorize, 'Inputs':names, 'Outputs':list(dls.categorize.vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def to_fastinference(x:TabularLearner, fname='export', path=Path('.')):\n",
    "    \"Export data for `fastinference_onnx` or `_pytorch` to use\"\n",
    "    procs = _get_procs(x.dls)\n",
    "    with open(path/f'{fname}.pkl', 'wb') as handle:\n",
    "        picle.dump(procs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Interpret():\n",
    "    def __init__(self, learn, df):\n",
    "        \"\"\"\n",
    "        MasterClass what knows how to deal with learner and dataframe\n",
    "        Now for classification only\n",
    "        \"\"\"\n",
    "        self.learn = learn\n",
    "        self.df = df\n",
    "\n",
    "    def _predict_row(self, row):\n",
    "        \"\"\"\n",
    "        Wrapper for prediction on a single row\n",
    "        \"\"\"\n",
    "        learn = self.learn\n",
    "        return float(learn.get_preds(dl=learn.dls.test_dl(pd.DataFrame([row])))[0][0][0])\n",
    "\n",
    "    def _predict_df(self, df=None, is_ret_actls=False):\n",
    "        \"\"\"\n",
    "        returns predictions of df with certain learner\n",
    "        \"\"\"\n",
    "        df = df if isNotNone(df) else self.df\n",
    "        if (is_ret_actls == False):\n",
    "            return np.array(self.learn.get_preds(dl=self.learn.dls.test_dl(df))[0].T[0])\n",
    "        else:\n",
    "            out = self.learn.get_preds(dl=self.learn.dls.test_dl(df))\n",
    "            return np.array(out[0].T[0]), np.array(out[1].T[0])\n",
    "\n",
    "    def _convert_dep_col(self, dep_col, use_log=False):\n",
    "        '''\n",
    "        Converts dataframe column, named \"depended column\", into tensor, that can later be used to compare with predictions.\n",
    "        Log will be applied if use_log is set True\n",
    "        '''\n",
    "        actls = self.df[dep_col].T.to_numpy()[np.newaxis].T.astype('float32')\n",
    "        actls = np.log(actls) if (use_log == True) else actls\n",
    "        return torch.tensor(actls)\n",
    "\n",
    "    def _list_to_key(self, field):\n",
    "        \"\"\"\n",
    "        Turns unhashable list of strings to hashable key\n",
    "        \"\"\"\n",
    "        return f\"{field}\" if isinstance(field, str) else ', '.join(f\"{e}\" for e in field)\n",
    "\n",
    "    def _sv_var(self, var, name, path: Path = None):\n",
    "        \"Save variable as pickle object to path with name\"\n",
    "        f = open(path / f\"{name}.pkl\", \"wb\")\n",
    "        dump(var, f)\n",
    "        f.close()\n",
    "\n",
    "    def _ld_var(self, name, path: Path = None):\n",
    "        \"Returns a pickle object from path with name\"\n",
    "\n",
    "        f = open(path / f\"{name}.pkl\", \"rb\")\n",
    "        var = load(f)\n",
    "        f.close()\n",
    "        return var\n",
    "\n",
    "    def _calc_loss(self, pred, targ):\n",
    "        '''\n",
    "        Calculates error from predictions and actuals with a learner loss function\n",
    "        '''\n",
    "        func = self.learn.loss_func\n",
    "        return func(torch.tensor(pred, device=default_device()), torch.tensor(targ, device=default_device()))\n",
    "\n",
    "    def _calc_error(self, df=None):\n",
    "        '''\n",
    "        Wrapping function to calculate error for new dataframe on existing learner (learn.model)\n",
    "        See following functions' docstrings for details\n",
    "        '''\n",
    "        df = df if isNotNone(df) else self.df\n",
    "        preds, actls = self._predict_df(df=df, is_ret_actls=True)\n",
    "        error = self._calc_loss(pred=preds, targ=actls)\n",
    "        return float(error)\n",
    "\n",
    "    def _get_cat_columns(self, is_wo_na=False):\n",
    "        if (is_wo_na == False):\n",
    "            return self.learn.dls.cat_names\n",
    "        else:\n",
    "            return self.learn.dls.cat_names.filter(lambda x: x[-3:] != \"_na\")\n",
    "\n",
    "    def _get_cont_columns(self):\n",
    "        return self.learn.dls.cont_names\n",
    "\n",
    "    def _get_all_columns(self):\n",
    "        return self._get_cat_columns() + self._get_cont_columns()\n",
    "\n",
    "    def _get_dep_var(self):\n",
    "        return self.learn.dls.y_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sv_var(var, name, path, bzipped=False):\n",
    "    \"Save variable as pickle object to path with name\"\n",
    "    if (bzipped == False):\n",
    "        f = open(path/f\"{name}.pkl\",\"wb\")\n",
    "    else:\n",
    "        f = BZ2File(path/f\"{name}.pkl.bz2\", \"wb\")\n",
    "    dump(var, f)\n",
    "    f.close()\n",
    "\n",
    "def ld_var(name, path, bzipped=False):\n",
    "    \"Returns a pickle object from path with name\"\n",
    "    if (bzipped == False):\n",
    "        f = open(path/f\"{name}.pkl\",\"rb\")\n",
    "    else:\n",
    "        f = BZ2File(path/f\"{name}.pkl.bz2\",\"rb\")\n",
    "    var = load(f)\n",
    "    f.close()\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _list_diff(list_1:list, list_2:list)->list:\n",
    "    \"Difference between first and second lists\"\n",
    "    diff = set(list_1) - set(list_2)\n",
    "    return [item for item in list_1 if item in diff]\n",
    "\n",
    "def list_diff(list1, list2, *args)->list:\n",
    "    \"Difference between first and any number of lists\"\n",
    "    diff = _list_diff(list1, list2)\n",
    "    for arg in args:\n",
    "        diff = _list_diff(diff, arg)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [\"1\", 2, 3, 4, \"5\", 77, -7]\n",
    "list_2 = [3, \"5\"]\n",
    "list_3 = [4, -7]\n",
    "list_4 = [\"bla-bla\", 0, 77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 2]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_diff(list_1, list_2, list_3, list_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(list_diff(list_1, list_2, list_3, list_4), ['1', 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def which_elms(values:list, in_list:list)->list:\n",
    "    '''\n",
    "    Just returns elements from values that are in list in_list\n",
    "    '''\n",
    "    return [x for x in values if (x in in_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, '5']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_elms(list_1, list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_elms(list_1, list_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(which_elms(list_1, list_2), [3, '5'])\n",
    "test_eq(which_elms(list_1, list_4), [77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_in_list(values:list, in_list:list)->bool:\n",
    "    '''\n",
    "    Just returns is any of the elements from values is in list in_list\n",
    "    '''\n",
    "    if (len(which_elms(values, in_list)) > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_in_list(list_1, [\"bla-bla\", 0, 77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_in_list(list_1, [\"bla-bla\", 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(is_in_list(list_1, [\"bla-bla\", 0, 77]), True)\n",
    "test_eq(is_in_list(list_1, [\"bla-bla\", 0]), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def listify(p=None, match=None):\n",
    "    \"Make `p` listy and the same length as `match`.\"\n",
    "    if p is None: p=[]\n",
    "    elif isinstance(p, str): p = [p]\n",
    "    else:\n",
    "        try: a = len(p)\n",
    "        except: p = [p]\n",
    "    n = match if type(match)==int else len(p) if match is None else len(match)\n",
    "    if len(p)==1: p = p * n\n",
    "    assert len(p)==n, f'List len mismatch ({len(p)} vs {n})'\n",
    "    return list(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(listify(None),[])\n",
    "test_eq(listify([1,2,3]),[1,2,3])\n",
    "test_eq(listify(1,match=[1,2,3]),[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def isNone(cond):\n",
    "    return cond is None\n",
    "\n",
    "def isNotNone(cond):\n",
    "    return cond is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(isNone(None),True)\n",
    "test_eq(isNone(\"None\"),False)\n",
    "test_eq(isNone(\"\"),False)\n",
    "test_eq(isNone(0),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(isNotNone(None),False)\n",
    "test_eq(isNotNone(\"None\"),True)\n",
    "test_eq(isNotNone(\"\"),True)\n",
    "test_eq(isNotNone(0),True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
